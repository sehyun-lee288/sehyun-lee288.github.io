<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <style>
    .results-carousel .item {
      font-size: 1.1em;
    }

    /* Corrected CSS to apply the shade to the entire container */
    .result-figure {
      margin: 40px 0; /* Adds top and bottom margin for separation */
      text-align: center;
      padding: 20px; /* Add padding inside the container for space */
      border-radius: 8px; /* Rounded corners for the entire block */
      box-shadow: 0 4px 20px rgba(153, 153, 153, 0.3); /* Subtle shadow for depth */
    }
    
    /* The image styling no longer needs the box-shadow */
    .result-figure img {
      max-width: 100%;
      height: auto;
      border-radius: 8px; /* You can keep rounded corners on the image itself */
    }
    
    .result-figure figcaption {
      margin-top: 15px;
      font-size: 1.1em;
      color: #333;
      font-style: italic;
    }

    /* Styling for the title within the caption */
    .result-figure figcaption h4 {
      font-size: 1.2em;
      font-style: normal;
      margin-bottom: 5px;
    }
  </style>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Granular Concept Circuits: <br />Toward a Fine-Grained Circuit Discovery for Concept Representations</h1>
            <h3 class="title is-3 publication-title">ICCV 2025</h3>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://www.linkedin.com/in/dahee-kwon-ai" target="_blank">Dahee Kwon<sup>1</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://www.linkedin.com/in/sehyun-lee-58b3791a7/" target="_blank">Sehyun Lee<sup>1</sup></a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://sailab.kaist.ac.kr" target="_blank">Jaesik Choi<sup>1,2</sup></a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>KAIST (Korea Advanced Institute of Science and Technology), <sup>2</sup>INEEJI</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://www.arxiv.org/abs/2508.01728" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="https://arxiv.org/pdf/2508.01728#page=11" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/daheekwon/GCC" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://www.arxiv.org/abs/2508.01728" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <!-- BibTex Link -->
              <span class="link-block">
                <a href="static/txt/bibtex.txt" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fa fa-at"></i>
                </span>
                <span>BibTex</span>
              </a>
            </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Main figure -->
 <section class="hero teaser">
  <div class="container ix-max-desktop">
    <div class="hero-body">
      <img src="static/images/main-figure_v5.png" alt="GCC_circuit"/>
      Beyond class label. GCC is a fine-grained
    </div>
  </div>
 </section>
<!-- End Main figure -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Deep vision models have achieved remarkable classification performance by leveraging a hierarchical architecture in which human-interpretable concepts emerge through the composition of individual neurons across layers. Given the distributed nature of representations, pinpointing where specific visual concepts are encoded within a model remains a crucial yet challenging task. In this paper, we introduce an effective circuit discovery method, called Granular Concept Circuit (GCC), in which each circuit represents a concept relevant to a given query. To construct each circuit, our method iteratively assesses inter-neuron connectivity, focusing on both functional dependencies and semantic alignment. By automatically discovering multiple circuits, each capturing specific concepts within that query, our approach offers a profound, concept-wise interpretation of models and is the first to identify circuits tied to specific visual concepts at a fine-grained level. We validate the versatility and effectiveness of GCCs across various deep image classification models.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Approach -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-2">Approach</h2>
      <p class="subtitle is-4" style="text-align: left;">
        Our method utilizes two score metrics to discover and visualize granular concept circuits.
      </p>

      <p>Our method introduces Granular Concept Circuits (GCCs), a novel approach to interpreting deep vision models. Given a query image, we identify a "circuit" of functionally connected neurons that represents a specific, fine-grained concept. This is a two-step process: we first discover the circuit's functional connections using a (a) <b>Neuron Sensitivity Score</b>, and then we ensure the circuit is semantically interpretable by applying a (b) <b>Semantic Flow Score</b>. This two-score approach is crucial because a connection might have a high functional score but a low semantic score.</p>

      <div class="result-figure">
        <figure>
          <img src="static/images/score_v6.png" alt="A diagram illustrating the two-score approach with a black root node and purple, orange, and green candidate nodes." />
          <figcaption>
            <p>
              For example, starting from the <b>black root node</b>, our method connects to the <b>orange node</b> because it has a high functional score and a high semantic flow, which represents a meaningful concept like "Fluffy Hair." We discard the connection to the <b>green node</b>, even though it has a high functional score, because its low semantic flow indicates it is not a semantically interpretable part of the circuit. The resulting circuits are visualized, providing a clear and interpretable view of the model's internal workings.
            </p>
          </figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>
<!-- End of Approach -->

<!-- Result -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Results</h2>

      <div class="result-figure">
        <p class="subtitle is-4">
          Single Query and Multiple Granular Concept Circuits
        </p>
        <figure>
          <img src="static/images/quali_total.png" alt="A collage of Granular Concept Circuits visualizations for different concepts in a vision model." style="max-height: 800px;" />
          <figcaption>Figure 1. GCCs discovered from a single query image.</figcaption>
        </figure>
      </div>

      <div class="result-figure">
        <p class="subtitle is-4">
          Model-agnostic Circuit Extraction
        </p>
        <figure>
          <img src="static/images/quali_vit.png" alt="Granular Concept Circuits visualized on a Vision Transformer (ViT)." style="max-height: 400px;" />
          <figcaption>Figure 2. Our method successfully adapts to Vision Transformer (ViT) architectures.</figcaption>
        </figure>
      </div>

      <div class="result-figure">
        <p class="subtitle is-4">
          Multiple Queries with Different Classes and Common GCCs
        </p>
        <figure>
          <img src="static/images/multiple_different_class_v3.png" alt="A visualization of Granular Concept Circuits for different classes of images." style="max-height: 400px;" />
          <figcaption>Figure 3. GCCs discovered across multiple classes, demonstrating common concept representations.</figcaption>
        </figure>
      </div>
    </div>
  </div>
</section>
<!-- End of Result -->

<!-- Auditing Misclassification -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-2">Auditing Misclassification</h2>
      <p class="subtitle is-4">
        Our method can be used to diagnose and explain why a model makes a specific misclassification.
      </p>

      <div class="result-figure">
        <figure>
          <img src="static/images/incorrect_v2.png" alt="A figure showing logit gain plots and a visualization of Granular Concept Circuits for a misclassified image." style="max-height: 300px;"/>
          <figcaption>
            <h4 class="title is-5 has-text-centered" style="margin-bottom: 0;">Analyzing a Misclassified Image</h4>
            <br>
            <p style="text-align: left;">
              The top bar plots show the logit gain when Granular Concept Circuits (GCCs) derived from a misclassified "Schipperke" example are either inhibited or stimulated. The model incorrectly classified this as a "Soccer ball."
            </p>
            <p style="text-align: left;">
              The bottom panel visualizes the most influential GCC, highlighting concepts related to both the incorrect prediction (soccer ball texture) and the correct one (black objects). This demonstrates how our method can pinpoint the specific circuits responsible for the model's error.
            </p>
          </figcaption>
        </figure>
      </div>

    </div>
  </div>
</section>
<!-- End of Auditing Misclassification -->


<!-- Qualitative Evaluation -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-2">Qualitative Evaluation</h2>

      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <div class="result-figure">
            <p class="subtitle is-4">
              Average Logit Drop After Ablating Neurons
            </p>
            <figure>
              <img src="static/images/table_logit_drop.png" alt="A table showing the average logit drop after ablating neurons." style="max-height: 300px;" />
              <figcaption>This table shows the impact of ablating our discovered circuits on the model's output. The significant logit drop demonstrates that GCCs are highly influential for classification decisions.</figcaption>
            </figure>
          </div>
        </div>
        
        <div class="item">
          <div class="result-figure">
            <p class="subtitle is-4">
              Insertion and Deletion Game
            </p>
            <figure>
              <img src="static/images/insert_delete.png" alt="An insertion-deletion graph showing the sensitivity of models to our discovered circuits." style="max-height: 300px;" />
              <figcaption>Our method extracts circuits that are highly influential for classification, as shown by the high insertion and low deletion scores.</figcaption>
            </figure>
          </div>
        </div>

        <div class="item">
          <div class="result-figure">
            <p class="subtitle is-4">
              User Study Responses
            </p>
            <figure>
              <img src="static/images/user_study.png" alt="Results from a user study evaluating the interpretability of Granular Concept Circuits." />
              <figcaption>Results from our user study (33 participants) show a high degree of agreement that Granular Concept Circuits (GCCs) provide meaningful insights into model behavior.</figcaption>
            </figure>
          </div>
        </div>

      </div>
    </div>
  </div>
</section>
<!-- End of Qualitative Evaluation -->




<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{kwon2025granular,
        title     = {Granular Concept Circuits: Toward a Fine-Grained Circuit Discovery for Concept Representations},
        author    = {Dahee Kwon and Sehyun Lee and Jaesik Choi},
        booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
        year      = {2025},
        pages     = {to appear}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

<!-- End of Statcounter Code -->

</body>
</html>